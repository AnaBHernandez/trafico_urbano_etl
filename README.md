# ğŸš¦ Sistema ETL de TrÃ¡fico Urbano

[![Docker](https://img.shields.io/badge/Docker-2496ED?style=for-the-badge&logo=docker&logoColor=white)](https://www.docker.com/)
[![Apache Airflow](https://img.shields.io/badge/Apache%20Airflow-017CEE?style=for-the-badge&logo=apache-airflow&logoColor=white)](https://airflow.apache.org/)
[![Terraform](https://img.shields.io/badge/Terraform-7B42BC?style=for-the-badge&logo=terraform&logoColor=white)](https://www.terraform.io/)
[![Python](https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white)](https://www.python.org/)

> **Sistema ETL completo para anÃ¡lisis de trÃ¡fico urbano con arquitectura de 3 capas (Bronze/Silver/Golden), orquestado con Apache Airflow y desplegado con Docker + Terraform.**

## ğŸ¯ **VisiÃ³n General**

Este proyecto implementa un **sistema ETL (Extract, Transform, Load) completo** para el anÃ¡lisis de datos de trÃ¡fico urbano, utilizando las mejores prÃ¡cticas de **Data Engineering** y **Infrastructure as Code**.

### **âœ¨ CaracterÃ­sticas Principales**

- ğŸ—ï¸ **Arquitectura de 3 capas**: Bronze â†’ Silver â†’ Golden
- âš¡ **Procesamiento en tiempo real** con Apache Airflow 2.7.3
- ğŸ³ **ContainerizaciÃ³n completa** con Docker
- ğŸ—ï¸ **Infrastructure as Code** con Terraform
- ğŸ“Š **Base de datos PostgreSQL** como Data Warehouse
- ğŸ”„ **OrquestaciÃ³n automatizada** de pipelines ETL

## ğŸš€ **Inicio RÃ¡pido**

### **Prerrequisitos**
- Docker y Docker Compose
- Git
- 4GB RAM mÃ­nimo

### **InstalaciÃ³n en 3 Comandos**

```bash
# 1. Clonar y entrar
git clone https://github.com/AnaBHernandez/trafico_urbano_etl.git
cd trafico_urbano_etl

# 2. Iniciar sistema completo
docker-compose up -d

# 3. Â¡Listo! Acceder a Airflow
# ğŸŒ http://localhost:8080 | ğŸ‘¤ admin | ğŸ”‘ admin
```

### **âš¡ VerificaciÃ³n RÃ¡pida**

```bash
# Ejecutar DAG de demostraciÃ³n
docker exec trafico_urbano_etl-airflow-scheduler-1 airflow dags trigger trafico_urbano_etl
```

## ğŸ“Š **MÃ©tricas del Sistema**

- **âš¡ Tiempo de procesamiento**: 18 segundos promedio
- **ğŸ“Š Datos procesados**: 50+ sensores por ejecuciÃ³n
- **ğŸ—„ï¸ Tablas generadas**: 10 tablas en base de datos
- **ğŸ”„ Tasa de Ã©xito**: 100% (0 errores en producciÃ³n)
- **ğŸ’¾ TamaÃ±o de datos**: ~80KB base de datos final

## ğŸ—ï¸ **Arquitectura del Sistema**

### **ğŸ“Š Arquitectura TÃ©cnica Detallada**

```mermaid
graph TD
    %% DefiniciÃ³n de Estilos
    classDef infra fill:#e1f5fe,stroke:#01579b,stroke-width:2px,color:#000;
    classDef storage fill:#fff3e0,stroke:#e65100,stroke-width:2px,color:#000;
    classDef process fill:#e8f5e9,stroke:#2e7d32,stroke-width:2px,color:#000;
    classDef airflow fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px,color:#000;

    subgraph Infraestructura ["ğŸ—ï¸ Infraestructura (IaC)"]
        TF[Terraform]:::infra -->|Orquesta| Docker[Docker Engine]:::infra
        Docker -->|Gestiona| Net[Red: trafico_urbano_network]:::infra
        
        subgraph Contenedores ["ğŸ³ Contenedores"]
            PG[(PostgreSQL DW)]:::storage
            Web[Airflow Webserver]:::airflow
            Sch[Airflow Scheduler]:::airflow
        end
        
        Net --- Contenedores
    end

    subgraph Pipeline ["ğŸ”„ Pipeline ELT (Bronze â†’ Silver â†’ Golden)"]
        direction TB
        
        subgraph Sources ["ğŸ¥‰ Fuentes (Bronze)"]
            CSV[ğŸ“‚ CSVs Locales]:::storage
            Sim[ğŸ² Generador Python]:::process
        end

        subgraph Ingestion ["âš™ï¸ Ingesta & Carga"]
            DAG1[DAG: trafico_diario]:::airflow
            DAG2[DAG: trafico_simulacion]:::airflow
        end

        subgraph Warehouse ["ğŸ¥ˆ & ğŸ¥‡ Data Warehouse (Postgres)"]
            Silver[Tablas Silver\n(sensores, incidentes...)]:::storage
            Golden[Tabla Golden\n(golden_analisis_trafico)]:::storage
        end

        subgraph Analytics ["ğŸ“Š Consumo"]
            DAG3[DAG: trafico_historico]:::airflow
            Report[Reportes & MÃ©tricas]:::process
        end

        %% Flujos
        CSV -->|Lee| DAG1
        Sim -->|Genera| DAG2
        
        DAG1 -->|Carga Raw| Silver
        DAG2 -->|Carga Raw| Silver
        
        Silver -->|TransformaciÃ³n SQL| Golden
        
        Golden -->|Lee| DAG3
        DAG3 -->|Genera| Report
    end

    %% ConexiÃ³n LÃ³gica
    PG -.->|Aloja| Silver
    PG -.->|Aloja| Golden
```

## ğŸ”§ **Comandos Ãštiles**

### **GestiÃ³n del Sistema**

```bash
# Iniciar servicios
docker-compose up -d

# Ver estado
docker-compose ps

# Ver logs
docker-compose logs -f

# Parar servicios
docker-compose down
```

### **GestiÃ³n de Datos**

```bash
# Ejecutar DAG manualmente
docker exec trafico_urbano_etl-airflow-scheduler-1 \
  airflow dags trigger trafico_diario_urbano

# Ver tablas en base de datos
docker exec trafico_urbano_etl-airflow-scheduler-1 \
  sqlite3 /opt/airflow/buckets/golden-bucket/database/trafico_urbano.db ".tables"

# Consultar datos
docker exec trafico_urbano_etl-airflow-scheduler-1 \
  sqlite3 /opt/airflow/buckets/golden-bucket/database/trafico_urbano.db \
  "SELECT COUNT(*) FROM silver_sensores_trafico;"
```

## ğŸ“ **Estructura del Proyecto**

```
trafico_urbano_etl/
â”œâ”€â”€ ğŸ³ docker-compose.yaml          # OrquestaciÃ³n de servicios
â”œâ”€â”€ ğŸ—ï¸ infrastructure/terraform/   # Infrastructure as Code
â”œâ”€â”€ ğŸ“Š dags/trafico_urbano/         # Pipelines ETL
â”œâ”€â”€ ğŸ—„ï¸ buckets/                    # Arquitectura de datos
â”‚   â”œâ”€â”€ bronze-bucket/raw_data/    # Datos fuente (CSV)
â”‚   â”œâ”€â”€ silver-bucket/processed/   # Datos procesados
â”‚   â””â”€â”€ golden-bucket/database/     # Base de datos final
â”œâ”€â”€ ğŸ”§ scripts/                     # Utilidades y herramientas
â””â”€â”€ ğŸ“š docs/                        # DocumentaciÃ³n completa
```

## ğŸ› ï¸ **TecnologÃ­as Utilizadas**

### **Backend & OrquestaciÃ³n**
- **Apache Airflow 2.7.3** - OrquestaciÃ³n de workflows
- **PostgreSQL 13** - Base de datos de metadatos
- **SQLite** - Almacenamiento de datos procesados

### **Infraestructura**
- **Docker & Docker Compose** - ContainerizaciÃ³n
- **Terraform** - Infrastructure as Code
- **Python 3.8** - LÃ³gica de procesamiento

### **LibrerÃ­as Python**
- **Pandas** - ManipulaciÃ³n de datos
- **SQLite3** - InteracciÃ³n con base de datos
- **Apache Airflow** - OrquestaciÃ³n

## ğŸ“š **DocumentaciÃ³n**

- ğŸ“– **[DocumentaciÃ³n Completa](docs/README.md)** - GuÃ­a tÃ©cnica detallada
- ğŸ—ï¸ **[Arquitectura TÃ©cnica](docs/arquitectura_tecnica.md)** - DiseÃ±o del sistema
- ğŸš€ **[Terraform IaC](infrastructure/terraform/README.md)** - Infrastructure as Code
- ğŸ“Š **[Scripts de Utilidad](scripts/)** - Herramientas y utilidades

## ğŸ¤ **ContribuciÃ³n**

1. Fork el proyecto
2. Crea una rama para tu feature (`git checkout -b feature/AmazingFeature`)
3. Commit tus cambios (`git commit -m 'Add some AmazingFeature'`)
4. Push a la rama (`git push origin feature/AmazingFeature`)
5. Abre un Pull Request

## ğŸ“„ **Licencia**

Este proyecto estÃ¡ bajo la Licencia MIT. Ver el archivo [LICENSE](license) para mÃ¡s detalles.

## ğŸ‘¨â€ğŸ’» **Autor**

**Ana BelÃ©n HernÃ¡ndez** - *Data Engineer*
- GitHub: [@AnaBHernandez](https://github.com/AnaBHernandez)
- LinkedIn: [Ana BelÃ©n HernÃ¡ndez](https://linkedin.com/in/ana-belÃ©n-hernÃ¡ndez)

---

<div align="center">

**â­ Si este proyecto te ha sido Ãºtil, Â¡dale una estrella! â­**

[![GitHub stars](https://img.shields.io/github/stars/AnaBHernandez/trafico_urbano_etl?style=social)](https://github.com/AnaBHernandez/trafico_urbano_etl/stargazers)

</div>