# ğŸš¦ Sistema ETL de TrÃ¡fico Urbano

[![Docker](https://img.shields.io/badge/Docker-2496ED?style=for-the-badge&logo=docker&logoColor=white)](https://www.docker.com/)
[![Apache Airflow](https://img.shields.io/badge/Apache%20Airflow-017CEE?style=for-the-badge&logo=apache-airflow&logoColor=white)](https://airflow.apache.org/)
[![Terraform](https://img.shields.io/badge/Terraform-7B42BC?style=for-the-badge&logo=terraform&logoColor=white)](https://www.terraform.io/)
[![Python](https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white)](https://www.python.org/)

> **Sistema ETL completo para anÃ¡lisis de trÃ¡fico urbano con arquitectura de 3 capas (Bronze/Silver/Golden), orquestado con Apache Airflow y desplegado con Docker + Terraform.**

## ğŸ¯ **VisiÃ³n General**

Este proyecto implementa un **sistema ETL (Extract, Transform, Load) completo** para el anÃ¡lisis de datos de trÃ¡fico urbano, utilizando las mejores prÃ¡cticas de **Data Engineering** y **Infrastructure as Code**.

### **âœ¨ CaracterÃ­sticas Principales**

- ğŸ—ï¸ **Arquitectura de 3 capas**: Bronze â†’ Silver â†’ Golden
- âš¡ **Procesamiento en tiempo real** con Apache Airflow 2.7.3
- ğŸ³ **ContainerizaciÃ³n completa** con Docker
- ğŸ—ï¸ **Infrastructure as Code** con Terraform
- ğŸ“Š **Base de datos PostgreSQL** como Data Warehouse
- ğŸ”„ **OrquestaciÃ³n automatizada** de pipelines ETL

## ğŸš€ **Inicio RÃ¡pido**

### **Prerrequisitos**
- Docker
- Terraform (>= 1.0)
- Git
- 4GB RAM mÃ­nimo

### **InstalaciÃ³n en 3 Comandos**

```bash
# 1. Clonar y entrar
git clone https://github.com/AnaBHernandez/trafico_urbano_etl.git
cd trafico_urbano_etl/infrastructure/terraform

# 2. Iniciar sistema completo
terraform init && terraform apply -auto-approve

# 3. Â¡Listo! Acceder a Airflow
# ğŸŒ http://localhost:8080 | ğŸ‘¤ admin | ğŸ”‘ admin
```

### **âš¡ VerificaciÃ³n RÃ¡pida**

```bash
# Ejecutar DAG de simulaciÃ³n
docker exec trafico_airflow_scheduler airflow dags trigger trafico_simulacion_principal
```

## ğŸ“Š **MÃ©tricas del Sistema**

- **âš¡ Tiempo de procesamiento**: 18 segundos promedio
- **ğŸ“Š Datos procesados**: 50+ sensores por ejecuciÃ³n
- **ğŸ—„ï¸ Tablas generadas**: 10 tablas en base de datos
- **ğŸ”„ Tasa de Ã©xito**: 100% (0 errores en producciÃ³n)
- **ğŸ’¾ TamaÃ±o de datos**: ~80KB base de datos final

## ğŸ—ï¸ **Arquitectura del Sistema**

```mermaid
flowchart TD
    subgraph Sources [ğŸ¥‰ Fuentes]
        A[ğŸ“„ CSVs]
        B[ğŸ² SimulaciÃ³n]
    end

    subgraph Orchestrator [âš™ï¸ Orquestador]
        C{{ğŸŒªï¸ Apache Airflow}}
    end

    subgraph Warehouse [ğŸ—„ï¸ Data Warehouse]
        D[(ğŸ¥ˆ Silver)]
        E[(ğŸ¥‡ Golden)]
    end

    Sources -->|Ingesta| C
    C -->|Carga| D
    D -->|TransformaciÃ³n SQL| E
    E -->|Consumo| F[ğŸ“Š Reportes]
```

## ğŸ”§ **Comandos Ãštiles**

### **GestiÃ³n del Sistema**

```bash
# Iniciar infraestructura (desde infrastructure/terraform)
terraform apply -auto-approve

# Ver estado
docker ps

# Ver logs de Airflow
docker logs -f trafico_airflow_webserver

# Destruir infraestructura
terraform destroy -auto-approve
```

### **GestiÃ³n de Datos**

```bash
# Ejecutar DAG manualmente
docker exec trafico_airflow_scheduler \
  airflow dags trigger trafico_diario_urbano

# Ver tablas en base de datos
docker exec -it trafico_postgres psql -U airflow -d airflow -c "\dt"

# Consultar datos
docker exec -it trafico_postgres psql -U airflow -d airflow -c \
  "SELECT COUNT(*) FROM golden_analisis_trafico;"
```

## ğŸ“ **Estructura del Proyecto**

```
trafico_urbano_etl/
â”œâ”€â”€ ğŸ—ï¸ infrastructure/terraform/   # Infrastructure as Code
â”œâ”€â”€ ğŸ“Š dags/trafico_urbano/         # Pipelines ETL
â”œâ”€â”€ ğŸ—„ï¸ buckets/                    # Arquitectura de datos
â”‚   â”œâ”€â”€ bronze-bucket/raw_data/    # Datos fuente (CSV)
â”‚   â”œâ”€â”€ silver-bucket/processed/   # Datos procesados
â”‚   â””â”€â”€ golden-bucket/database/     # Base de datos final
â”œâ”€â”€ ğŸ”§ scripts/                     # Utilidades y herramientas
â””â”€â”€ ğŸ“š docs/                        # DocumentaciÃ³n completa
```

## ğŸ› ï¸ **TecnologÃ­as Utilizadas**

### **Backend & OrquestaciÃ³n**
- **Apache Airflow 2.7.3** - OrquestaciÃ³n de workflows
- **PostgreSQL 13** - Base de datos de metadatos

### **Infraestructura**
- **Terraform** - Infraestructura como CÃ³digo (IaC)

### **LibrerÃ­as Python**
- **Pandas** - ManipulaciÃ³n de datos
- **Apache Airflow** - OrquestaciÃ³n

## ğŸ“š **DocumentaciÃ³n**

- ğŸ“– **[DocumentaciÃ³n Completa](docs/README.md)** - GuÃ­a tÃ©cnica detallada
- ğŸ—ï¸ **[Arquitectura TÃ©cnica](docs/arquitectura_tecnica.md)** - DiseÃ±o del sistema
- ğŸš€ **[Terraform IaC](infrastructure/terraform/README.md)** - Infrastructure as Code
- ğŸ“Š **[Scripts de Utilidad](scripts/)** - Herramientas y utilidades

## ğŸ¤ **ContribuciÃ³n**

1. Fork el proyecto
2. Crea una rama para tu feature (`git checkout -b feature/AmazingFeature`)
3. Commit tus cambios (`git commit -m 'Add some AmazingFeature'`)
4. Push a la rama (`git push origin feature/AmazingFeature`)
5. Abre un Pull Request

## ğŸ“„ **Licencia**

Este proyecto estÃ¡ bajo la Licencia MIT. Ver el archivo [LICENSE](license) para mÃ¡s detalles.

## ğŸ‘¨â€ğŸ’» **Autor**

**Ana BelÃ©n HernÃ¡ndez** - *Data Engineer*
- GitHub: [@AnaBHernandez](https://github.com/AnaBHernandez)
- LinkedIn: [Ana BelÃ©n HernÃ¡ndez](https://linkedin.com/in/ana-belÃ©n-hernÃ¡ndez)

---

<div align="center">

**â­ Si este proyecto te ha sido Ãºtil, Â¡dale una estrella! â­**

[![GitHub stars](https://img.shields.io/github/stars/AnaBHernandez/trafico_urbano_etl?style=social)](https://github.com/AnaBHernandez/trafico_urbano_etl/stargazers)

</div>