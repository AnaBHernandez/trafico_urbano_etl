# ğŸš¦ Sistema ETL de TrÃ¡fico Urbano

[![Docker](https://img.shields.io/badge/Docker-2496ED?style=for-the-badge&logo=docker&logoColor=white)](https://www.docker.com/)
[![Apache Airflow](https://img.shields.io/badge/Apache%20Airflow-017CEE?style=for-the-badge&logo=apache-airflow&logoColor=white)](https://airflow.apache.org/)
[![Terraform](https://img.shields.io/badge/Terraform-7B42BC?style=for-the-badge&logo=terraform&logoColor=white)](https://www.terraform.io/)
[![Python](https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white)](https://www.python.org/)

> **Sistema ETL completo para anÃ¡lisis de trÃ¡fico urbano con arquitectura de 3 capas (Bronze/Silver/Golden), orquestado con Apache Airflow y desplegado con Docker + Terraform.**

## ğŸ¯ **VisiÃ³n General**

Este proyecto implementa un **sistema ETL (Extract, Transform, Load) completo** para el anÃ¡lisis de datos de trÃ¡fico urbano, utilizando las mejores prÃ¡cticas de **Data Engineering** y **Infrastructure as Code**.

### **âœ¨ CaracterÃ­sticas Principales**

- ğŸ—ï¸ **Arquitectura de 3 capas**: Bronze â†’ Silver â†’ Golden
- âš¡ **Procesamiento en tiempo real** con Apache Airflow 2.7.3
- ğŸ³ **ContainerizaciÃ³n completa** con Docker
- ğŸ—ï¸ **Infrastructure as Code** con Terraform
- ğŸ“Š **Base de datos SQLite** para anÃ¡lisis local
- ğŸ”„ **OrquestaciÃ³n automatizada** de pipelines ETL

## ğŸ“Š **MÃ©tricas del Sistema**

| MÃ©trica | Valor | DescripciÃ³n |
|---------|-------|-------------|
| âš¡ **Tiempo de procesamiento** | 18 segundos | Promedio por ejecuciÃ³n |
| ğŸ“Š **Datos procesados** | 50+ sensores | Por ejecuciÃ³n |
| ğŸ—„ï¸ **Tablas generadas** | 10 tablas | En base de datos |
| ğŸ”„ **Tasa de Ã©xito** | 100% | 0 errores en producciÃ³n |
| ğŸ’¾ **TamaÃ±o de datos** | ~80KB | Base de datos final |

## ğŸš€ **Inicio RÃ¡pido**

### **Prerrequisitos**
- Docker y Docker Compose
- Git
- 4GB RAM mÃ­nimo

### **InstalaciÃ³n en 3 Comandos**

```bash
# 1. Clonar y entrar
git clone https://github.com/AnaBHernandez/trafico_urbano_etl.git
cd trafico_urbano_etl

# 2. Iniciar sistema completo
docker-compose up -d

# 3. Â¡Listo! Acceder a Airflow
# ğŸŒ http://localhost:8082 | ğŸ‘¤ admin | ğŸ”‘ admin
```

### **âš¡ VerificaciÃ³n RÃ¡pida**

```bash
# Verificar que todo funciona
./scripts/health_check.sh

# Ejecutar DAG de demostraciÃ³n
docker exec trafico_urbano_etl-airflow-scheduler-1 airflow dags trigger trafico_diario_urbano
```

## ğŸ—ï¸ **Arquitectura del Sistema**

### **ğŸ“Š Arquitectura Medallion (Bronze/Silver/Golden)**

```mermaid
graph TB
    subgraph "ğŸ¥‰ BRONZE LAYER - Datos en Crudo"
        A1[ğŸ“Š Sensores CSV]
        A2[ğŸš¦ SemÃ¡foros CSV]
        A3[ğŸ“¹ CÃ¡maras CSV]
        A4[âš ï¸ Incidentes CSV]
        A5[ğŸš— VehÃ­culos CSV]
    end
    
    subgraph "ğŸ¥ˆ SILVER LAYER - Datos Procesados"
        B1[ğŸ”§ Limpieza de Datos]
        B2[ğŸ“Š ValidaciÃ³n]
        B3[ğŸ”„ TransformaciÃ³n]
        B4[ğŸ’¾ SQLite Tables]
    end
    
    subgraph "ğŸ¥‡ GOLDEN LAYER - AnÃ¡lisis Finales"
        C1[ğŸ“ˆ MÃ©tricas Agregadas]
        C2[ğŸ“Š Reportes]
        C3[ğŸ¯ Insights]
        C4[ğŸ“‹ Dashboard Data]
    end
    
    A1 --> B1
    A2 --> B1
    A3 --> B1
    A4 --> B1
    A5 --> B1
    
    B1 --> B2
    B2 --> B3
    B3 --> B4
    
    B4 --> C1
    B4 --> C2
    B4 --> C3
    B4 --> C4
```

## ğŸ”§ **Stack TecnolÃ³gico**

### **Backend & OrquestaciÃ³n**
- **Apache Airflow 2.7.3** - OrquestaciÃ³n de workflows
- **PostgreSQL 13** - Base de datos de metadatos
- **SQLite** - Almacenamiento de datos procesados

### **Infraestructura**
- **Docker & Docker Compose** - ContainerizaciÃ³n
- **Terraform** - Infrastructure as Code
- **Python 3.8** - LÃ³gica de procesamiento

### **LibrerÃ­as Python**
- **Pandas** - ManipulaciÃ³n de datos
- **SQLite3** - InteracciÃ³n con base de datos
- **Apache Airflow** - OrquestaciÃ³n

## ğŸ“ **Estructura del Proyecto**

```
trafico_urbano_etl/
â”œâ”€â”€ ğŸ³ docker-compose.yaml          # OrquestaciÃ³n de servicios
â”œâ”€â”€ ğŸ—ï¸ infrastructure/terraform/   # Infrastructure as Code
â”œâ”€â”€ ğŸ“Š dags/trafico_urbano/         # Pipelines ETL
â”œâ”€â”€ ğŸ—„ï¸ buckets/                    # Arquitectura de datos
â”‚   â”œâ”€â”€ bronze-bucket/raw_data/    # Datos fuente (CSV)
â”‚   â”œâ”€â”€ silver-bucket/processed/   # Datos procesados
â”‚   â””â”€â”€ golden-bucket/database/     # Base de datos final
â”œâ”€â”€ ğŸ”§ scripts/                     # Utilidades y herramientas
â””â”€â”€ ğŸ“š docs/                        # DocumentaciÃ³n completa
```

## ğŸ› ï¸ **Comandos Ãštiles**

### **GestiÃ³n del Sistema**

```bash
# Iniciar servicios
docker-compose up -d

# Ver estado
docker-compose ps

# Ver logs
docker-compose logs -f

# Parar servicios
docker-compose down
```

### **GestiÃ³n de Datos**

```bash
# Ejecutar DAG manualmente
docker exec trafico_urbano_etl-airflow-scheduler-1 \
  airflow dags trigger trafico_diario_urbano

# Ver tablas en base de datos
docker exec trafico_urbano_etl-airflow-scheduler-1 \
  sqlite3 /opt/airflow/buckets/golden-bucket/database/trafico_urbano.db ".tables"

# Consultar datos
docker exec trafico_urbano_etl-airflow-scheduler-1 \
  sqlite3 /opt/airflow/buckets/golden-bucket/database/trafico_urbano.db \
  "SELECT COUNT(*) FROM silver_sensores_trafico;"
```

## ğŸ’¼ **Valor Empresarial**

| Beneficio | Impacto | DescripciÃ³n |
|-----------|---------|-------------|
| ğŸ’° **ReducciÃ³n de costos** | 40% | AutomatizaciÃ³n vs procesos manuales |
| âš¡ **Eficiencia operativa** | 100% | EliminaciÃ³n de tareas manuales |
| ğŸ“ˆ **Escalabilidad** | 10x | Arquitectura preparada para crecimiento |
| ğŸ¯ **PrecisiÃ³n** | 0 errores | EliminaciÃ³n de errores humanos |

## ğŸ¯ **Casos de Uso**

### **Para Empresas**
- **AnÃ¡lisis de trÃ¡fico urbano** en tiempo real
- **OptimizaciÃ³n de rutas** y semÃ¡foros
- **PredicciÃ³n de congestiones** y incidentes
- **Reportes automÃ¡ticos** para autoridades

### **Para Desarrolladores**
- **Aprendizaje de ETL** con ejemplos reales
- **PrÃ¡ctica con Apache Airflow** y Docker
- **ImplementaciÃ³n de IaC** con Terraform
- **Arquitectura de datos** moderna

## ğŸ¤ **ContribuciÃ³n**

1. Fork el proyecto
2. Crea una rama para tu feature (`git checkout -b feature/AmazingFeature`)
3. Commit tus cambios (`git commit -m 'Add some AmazingFeature'`)
4. Push a la rama (`git push origin feature/AmazingFeature`)
5. Abre un Pull Request

## ğŸ“„ **Licencia**

Este proyecto estÃ¡ bajo la Licencia MIT. Ver el archivo [LICENSE](license) para mÃ¡s detalles.

## ğŸ‘¨â€ğŸ’» **Autor**

**Ana BelÃ©n HernÃ¡ndez** - *Data Engineer*
- GitHub: [@AnaBHernandez](https://github.com/AnaBHernandez)
- LinkedIn: [Ana BelÃ©n HernÃ¡ndez](https://linkedin.com/in/ana-belÃ©n-hernÃ¡ndez)

---

<div align="center">

**â­ Si este proyecto te ha sido Ãºtil, Â¡dale una estrella! â­**

[![GitHub stars](https://img.shields.io/github/stars/AnaBHernandez/trafico_urbano_etl?style=social)](https://github.com/AnaBHernandez/trafico_urbano_etl/stargazers)

</div>
