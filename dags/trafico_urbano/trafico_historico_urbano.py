# DAG HISTÃ“RICO - AnÃ¡lisis de TrÃ¡fico Urbano - COMPLETAMENTE OPTIMIZADO
# Fecha: 24 Septiembre 2025
# PropÃ³sito: AnÃ¡lisis histÃ³rico de trÃ¡fico urbano - MÃXIMO 10 MINUTOS
# Estado: MANUAL (desarrollo/formaciÃ³n)
# OPTIMIZACIÃ“N: AnÃ¡lisis de datos histÃ³ricos

import pendulum
from airflow.models.dag import DAG
from airflow.operators.dummy import DummyOperator
from airflow.operators.python import PythonOperator

# =====================================================
# VARIABLES DE CONFIGURACIÃ“N
# =====================================================
DB_PATH = '/opt/airflow/buckets/golden-bucket/database/trafico_urbano.db'
DAG_ID = 'trafico_historico_urbano'

# =====================================================
# FUNCIONES PYTHON PARA REEMPLAZAR SQLiteOperator
# =====================================================


def analizar_congestiones_historicas(**context):
    """Analiza congestiones histÃ³ricas por ubicaciÃ³n"""
    import sqlite3

    conn = sqlite3.connect(DB_PATH)
    cursor = conn.cursor()

    cursor.execute("""
        SELECT
            ubicacion,
            COUNT(*) as total_congestiones,
            AVG(ocupacion_porcentaje) as ocupacion_promedio,
            MAX(ocupacion_porcentaje) as ocupacion_maxima
        FROM golden_analisis_trafico
        WHERE ocupacion_porcentaje > 80
        AND DATE(analyzed_at) >= DATE('now', '-30 days')
        GROUP BY ubicacion
        ORDER BY total_congestiones DESC
        LIMIT 10
    """)

    resultados = cursor.fetchall()

    print("ğŸ“Š ANÃLISIS DE CONGESTIONES HISTÃ“RICAS:")
    for ubicacion, total, promedio, maxima in resultados:
        print(
            f"  â€¢ {ubicacion}: {total} congestiones, "
            f"{promedio:.1f}% promedio, {maxima:.1f}% mÃ¡xima"
        )

    conn.close()
    return f"Congestiones analizadas: {len(resultados)} ubicaciones"


def analizar_tendencias_historicas(**context):
    """Analiza tendencias histÃ³ricas de trÃ¡fico"""
    import sqlite3
    import pandas as pd

    conn = sqlite3.connect(DB_PATH)

    query = """
        SELECT
            strftime('%H', analyzed_at) as hora,
            AVG(velocidad_promedio) as velocidad_promedio,
            AVG(vehiculos_por_hora) as vehiculos_promedio,
            AVG(ocupacion_porcentaje) as ocupacion_promedio
        FROM golden_analisis_trafico
        WHERE DATE(analyzed_at) >= DATE('now', '-30 days')
        GROUP BY strftime('%H', analyzed_at)
        ORDER BY hora
    """

    df = pd.read_sql_query(query, conn)
    conn.close()

    print("ğŸ“ˆ TENDENCIAS HISTÃ“RICAS DE TRÃFICO:")
    print("  - PerÃ­odo analizado: Ãšltimos 30 dÃ­as")
    print(f"  - Registros procesados: {len(df)}")

    if len(df) > 0:
        print("  - Patrones identificados:")
        print(f"    â€¢ Hora pico: {df.loc[df['vehiculos_promedio'].idxmax(), 'hora']}:00")
        print(f"    â€¢ Velocidad promedio: {df['velocidad_promedio'].mean():.1f} km/h")
        print(f"    â€¢ OcupaciÃ³n promedio: {df['ocupacion_promedio'].mean():.1f}%")

    return f"Tendencias analizadas: {len(df)} perÃ­odos"


def metricas_rendimiento_historico(**context):
    """Genera mÃ©tricas de rendimiento histÃ³rico"""
    import sqlite3

    conn = sqlite3.connect(DB_PATH)
    cursor = conn.cursor()

    # MÃ©tricas generales
    cursor.execute("SELECT COUNT(*) FROM golden_analisis_trafico")
    total_registros = cursor.fetchone()[0]

    cursor.execute("""
        SELECT AVG(velocidad_promedio) FROM golden_analisis_trafico
        WHERE DATE(analyzed_at) >= DATE('now', '-7 days')
    """)
    velocidad_semanal = cursor.fetchone()[0] or 0

    cursor.execute("""
        SELECT AVG(ocupacion_porcentaje) FROM golden_analisis_trafico
        WHERE DATE(analyzed_at) >= DATE('now', '-7 days')
    """)
    ocupacion_semanal = cursor.fetchone()[0] or 0

    conn.close()

    print("ğŸ“Š MÃ‰TRICAS DE RENDIMIENTO HISTÃ“RICO:")
    print(f"  - Total de registros: {total_registros}")
    print(f"  - Velocidad promedio (7 dÃ­as): {velocidad_semanal:.1f} km/h")
    print(f"  - OcupaciÃ³n promedio (7 dÃ­as): {ocupacion_semanal:.1f}%")

    return f"MÃ©tricas generadas: {total_registros} registros histÃ³ricos"


def generar_reporte_semanal(**context):
    """Genera reporte semanal consolidado"""
    import sqlite3
    import pandas as pd

    conn = sqlite3.connect(DB_PATH)

    query = """
        SELECT
            DATE(analyzed_at) as fecha,
            COUNT(*) as registros,
            AVG(velocidad_promedio) as velocidad_promedio,
            AVG(vehiculos_por_hora) as vehiculos_promedio,
            AVG(ocupacion_porcentaje) as ocupacion_promedio
        FROM golden_analisis_trafico
        WHERE DATE(analyzed_at) >= DATE('now', '-7 days')
        GROUP BY DATE(analyzed_at)
        ORDER BY fecha
    """

    df = pd.read_sql_query(query, conn)
    conn.close()

    print("ğŸ“ˆ REPORTE SEMANAL DE TRÃFICO:")
    print("  - PerÃ­odo: Ãšltimos 7 dÃ­as")
    print(f"  - Registros analizados: {len(df)}")

    if len(df) > 0:
        print("  - Resumen semanal:")
        print(f"    â€¢ DÃ­as con datos: {len(df)}")
        print(f"    â€¢ Velocidad promedio: {df['velocidad_promedio'].mean():.1f} km/h")
        print(f"    â€¢ VehÃ­culos promedio: {df['vehiculos_promedio'].mean():.1f}/h")
        print(f"    â€¢ OcupaciÃ³n promedio: {df['ocupacion_promedio'].mean():.1f}%")

    return f"Reporte semanal generado: {len(df)} dÃ­as analizados"


# =====================================================
# CONFIGURACIÃ“N DEL DAG
# =====================================================
default_args = {
    'owner': 'ana-hernandez',
    'depends_on_past': False,
    'start_date': pendulum.datetime(2025, 9, 24, tz="UTC"),
    'retries': 0,
    'email_on_failure': False,
    'email_on_retry': False,
    'catchup': False
}

dag = DAG(
    DAG_ID,
    default_args=default_args,
    description='AnÃ¡lisis histÃ³rico de trÃ¡fico urbano',
    schedule_interval='@weekly',
    catchup=False,
    tags=['trafico', 'historico', 'analisis']
)

# =====================================================
# TAREAS DEL DAG
# =====================================================
start = DummyOperator(
    task_id='start',
    dag=dag
)

# Tareas de anÃ¡lisis histÃ³rico
analyze_congestiones = PythonOperator(
    task_id='analizar_congestiones_historicas',
    python_callable=analizar_congestiones_historicas,
    dag=dag
)

analyze_tendencias = PythonOperator(
    task_id='analizar_tendencias_historicas',
    python_callable=analizar_tendencias_historicas,
    dag=dag
)

generate_metrics = PythonOperator(
    task_id='metricas_rendimiento_historico',
    python_callable=metricas_rendimiento_historico,
    dag=dag
)

generate_report = PythonOperator(
    task_id='generar_reporte_semanal',
    python_callable=generar_reporte_semanal,
    dag=dag
)

end = DummyOperator(
    task_id='end',
    dag=dag
)

# =====================================================
# DEPENDENCIAS DEL DAG
# =====================================================
start >> [analyze_congestiones, analyze_tendencias] >> generate_metrics >> generate_report >> end
